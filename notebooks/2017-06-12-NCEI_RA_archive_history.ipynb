{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using NCEI geoportal REST API to collect information about IOOS Regional Association archived data\n",
    "\n",
    "by Mathew Biddle, Faculty Specialist, UMD/ESSIC/CICS at the NOAA National Centers for Environmental Information (NCEI)\n",
    "\n",
    "### IOOS regional associations archive their non-federal observational data with NOAA's National Center for Environmental Information (NCEI). In this notebook we will use the [RESTful](https://github.com/Esri/geoportal-server/wiki/REST-API-Syntax) services of the [NCEI geoportal](https://www.nodc.noaa.gov/archivesearch/catalog/search/search.page) to collect metadata from the Archival Information Packages found in the NCEI archives. The metadata information are stored in [ISO 19115-2](https://wiki.earthdata.nasa.gov/display/NASAISO/ISO+19115-2) xml files which the NCEI geoportal uses for discovery of Archival Information Packages (AIPs). This example uses the ISO metadata records to display publication information as well as plot the time coverage of each AIP at NCEI which meets the search criteria.\n",
    "\n",
    "First we import the owslib and numpy package. This allows us to parse the ISO xml records and process the information we gather.\n",
    "\n",
    "Initialize a counter for plotting and a list to collect the NCEI Accession identifiers (we use this in the plotting routine). Also, update the namespaces dictionary from owslib to include the appropriate namespace reference for gmi and gml. \n",
    "\n",
    "For more information on ISO Namespaces see:  https://geo-ide.noaa.gov/wiki/index.php?title=ISO_Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owslib.iso import namespaces\n",
    "\n",
    "# Append gmi namespace to namespaces dictionary.\n",
    "namespaces.update({\"gmi\": \"http://www.isotc211.org/2005/gmi\"})\n",
    "namespaces.update({\"gml\": \"http://www.opengis.net/gml/3.2\"})\n",
    "del namespaces[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we select a Regional Association \n",
    "This is where the user identifies the Regional Association they are interested in. Simply uncomment the line that identifies the region of interest. The user can also omit the Regional Association to collect metadata information about all IOOS non-Federal observation data archived through the NCEI-IOOS pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select RA\n",
    "\n",
    "RAs = {\n",
    "    \"GLOS\": \"Great Lakes Observing System\",\n",
    "    \"SCCOOS\": \"Southern California Coastal Ocean Observing System\",\n",
    "    \"SECOORA\": \"Southeast Coastal Ocean Observing Regional Association\",\n",
    "    \"PacIOOS\": \"Pacific Islands Ocean Observing System\",\n",
    "    \"NANOOS\": \"Northwest Association of Networked Ocean Observing Systems\",\n",
    "}\n",
    "\n",
    "ra = RAs[\"SCCOOS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we generate a geoportal query and georss feed\n",
    "To find more information about how to compile a geoportal query, have a look at [REST API Syntax](https://github.com/Esri/geoportal-server/wiki/REST-API-Syntax) and the [NCEI Search Tips](https://www.nodc.noaa.gov/search/granule/catalog/searchtips/searchtips.page) for the [NCEI geoportal](https://data.nodc.noaa.gov/geoportal/catalog/search/search.page). The example provided is specific to the NCEI-IOOS data pipeline project and only searches for non-federal timeseries data collected by each Regional Association. \n",
    "\n",
    "The query developed here can be updated to search for any Archival Information Packages at NCEI, therefore the user should develop the appropriate query using the [NCEI Geoportal](https://data.nodc.noaa.gov/geoportal/catalog/search/search.page) and update this portion of the code to identify the REST API of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified response format:\n",
      "https://www.ncei.noaa.gov/metadata/geoportal/opensearch?q=%28%22Integrated%20Ocean%20Observing%20System%20Data%20Assembly%20Centers%20Data%20Stewardship%20Program%22%20AND%20%22Southern%20California%20Coastal%20Ocean%20Observing%20System%22%20AND%20%22FIXED%20PLATFORM%22%29&start=1&num=1010&f=csv\n",
      "\n",
      "Search page response:\n",
      "https://www.ncei.noaa.gov/metadata/geoportal/opensearch?q=%28%22Integrated%20Ocean%20Observing%20System%20Data%20Assembly%20Centers%20Data%20Stewardship%20Program%22%20AND%20%22Southern%20California%20Coastal%20Ocean%20Observing%20System%22%20AND%20%22FIXED%20PLATFORM%22%29&start=1&num=1010&f=searchPage\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from urllib.parse import quote\n",
    "except ImportError:\n",
    "    from urllib import quote\n",
    "\n",
    "# Generate geoportal query and georss feed.\n",
    "\n",
    "# Base geoportal url.\n",
    "baseurl = \"https://www.ncei.noaa.gov/\" \"metadata/geoportal/opensearch\" \"?q=\" #\"dataThemeprojects_s:\"\n",
    "\n",
    "# Identify the project.\n",
    "project = (\n",
    "    '\"Integrated Ocean Observing System Data Assembly Centers Data Stewardship Program\"'\n",
    "#    ' OR \"HFRadarRadial\"'\n",
    "#    ' OR \"HFRadarRTVector\"'\n",
    ")\n",
    "\n",
    "# Identify the Regional Association\n",
    "ra = ' AND \"{}\" '.format(ra)\n",
    "\n",
    "# Identify the platform.\n",
    "platform = 'AND \"FIXED PLATFORM\"'\n",
    "\n",
    "# Identify the amount of records and format of the response: 1 to 1010 records.\n",
    "records = \"&start=1&num=1010\"\n",
    "\n",
    "# Identify the format of the response: georss.\n",
    "response_format = \"&f=csv\"\n",
    "\n",
    "# Combine the URL.\n",
    "url = \"{}{}\".format(baseurl, quote( '(' + project + ra + platform + ')' ) + records + response_format)\n",
    "\n",
    "print(\"Identified response format:\\n{}\".format(url))\n",
    "print(\n",
    "    \"\\nSearch page response:\\n{}\".format(url.replace(response_format, \"&f=searchPage\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to query the portal and parse out the csv response\n",
    "Here we are opening the specified REST API and parsing it into a string. Then, since we identified it as a csv format above, we parse it using the Pandas package. We also split the Data_Date_Range column into two columns, `data_start_date` and `data_end_date` to have that useful information available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>West</th>\n",
       "      <th>South</th>\n",
       "      <th>East</th>\n",
       "      <th>North</th>\n",
       "      <th>Link_Xml</th>\n",
       "      <th>Link_1</th>\n",
       "      <th>Link_2</th>\n",
       "      <th>Link_3</th>\n",
       "      <th>Link_4</th>\n",
       "      <th>Data_Date_Range</th>\n",
       "      <th>Date_Published</th>\n",
       "      <th>data_start_date</th>\n",
       "      <th>data_end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gov.noaa.nodc:0157035</td>\n",
       "      <td>Oceanographic data collected from station Scri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-117.2570</td>\n",
       "      <td>32.8670</td>\n",
       "      <td>-117.2570</td>\n",
       "      <td>32.8670</td>\n",
       "      <td>http://www.ncei.noaa.gov/metadata/geoportal/re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-06-16T00:00:00Z to 2020-12-31T23:59:59.999Z</td>\n",
       "      <td>2016-11-23T00:00:00Z</td>\n",
       "      <td>2005-06-16 00:00:00+00:00</td>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gov.noaa.nodc:0166465</td>\n",
       "      <td>Oceanographic data collected from station Burk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-117.3390</td>\n",
       "      <td>33.1390</td>\n",
       "      <td>-117.3390</td>\n",
       "      <td>33.1390</td>\n",
       "      <td>http://www.ncei.noaa.gov/metadata/geoportal/re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-14T00:00:00Z to 2019-02-06T23:59:59.999Z</td>\n",
       "      <td>2017-09-09T00:00:00Z</td>\n",
       "      <td>2015-02-14 00:00:00+00:00</td>\n",
       "      <td>2019-02-07 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gov.noaa.nodc:0157034</td>\n",
       "      <td>Oceanographic data collected from station Newp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-117.9311</td>\n",
       "      <td>33.6061</td>\n",
       "      <td>-117.9311</td>\n",
       "      <td>33.6061</td>\n",
       "      <td>http://www.ncei.noaa.gov/metadata/geoportal/re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-06-16T00:00:00Z to 2020-12-31T23:59:59.999Z</td>\n",
       "      <td>2016-11-23T00:00:00Z</td>\n",
       "      <td>2005-06-16 00:00:00+00:00</td>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gov.noaa.nodc:0157016</td>\n",
       "      <td>Oceanographic data collected from station Sant...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-118.4990</td>\n",
       "      <td>34.0080</td>\n",
       "      <td>-118.4990</td>\n",
       "      <td>34.0080</td>\n",
       "      <td>http://www.ncei.noaa.gov/metadata/geoportal/re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-06-16T00:00:00Z to 2020-12-31T23:59:59.999Z</td>\n",
       "      <td>2016-11-22T00:00:00Z</td>\n",
       "      <td>2005-06-16 00:00:00+00:00</td>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gov.noaa.nodc:0157036</td>\n",
       "      <td>Oceanographic data collected from station Stea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-119.6850</td>\n",
       "      <td>34.4080</td>\n",
       "      <td>-119.6850</td>\n",
       "      <td>34.4080</td>\n",
       "      <td>http://www.ncei.noaa.gov/metadata/geoportal/re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-09-16T00:00:00Z to 2020-12-31T23:59:59.999Z</td>\n",
       "      <td>2016-11-23T00:00:00Z</td>\n",
       "      <td>2005-09-16 00:00:00+00:00</td>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Id                                              Title  \\\n",
       "0  gov.noaa.nodc:0157035  Oceanographic data collected from station Scri...   \n",
       "1  gov.noaa.nodc:0166465  Oceanographic data collected from station Burk...   \n",
       "2  gov.noaa.nodc:0157034  Oceanographic data collected from station Newp...   \n",
       "3  gov.noaa.nodc:0157016  Oceanographic data collected from station Sant...   \n",
       "4  gov.noaa.nodc:0157036  Oceanographic data collected from station Stea...   \n",
       "\n",
       "   Description      West    South      East    North  \\\n",
       "0          NaN -117.2570  32.8670 -117.2570  32.8670   \n",
       "1          NaN -117.3390  33.1390 -117.3390  33.1390   \n",
       "2          NaN -117.9311  33.6061 -117.9311  33.6061   \n",
       "3          NaN -118.4990  34.0080 -118.4990  34.0080   \n",
       "4          NaN -119.6850  34.4080 -119.6850  34.4080   \n",
       "\n",
       "                                            Link_Xml  Link_1  Link_2  Link_3  \\\n",
       "0  http://www.ncei.noaa.gov/metadata/geoportal/re...     NaN     NaN     NaN   \n",
       "1  http://www.ncei.noaa.gov/metadata/geoportal/re...     NaN     NaN     NaN   \n",
       "2  http://www.ncei.noaa.gov/metadata/geoportal/re...     NaN     NaN     NaN   \n",
       "3  http://www.ncei.noaa.gov/metadata/geoportal/re...     NaN     NaN     NaN   \n",
       "4  http://www.ncei.noaa.gov/metadata/geoportal/re...     NaN     NaN     NaN   \n",
       "\n",
       "   Link_4                                   Data_Date_Range  \\\n",
       "0     NaN  2005-06-16T00:00:00Z to 2020-12-31T23:59:59.999Z   \n",
       "1     NaN  2015-02-14T00:00:00Z to 2019-02-06T23:59:59.999Z   \n",
       "2     NaN  2005-06-16T00:00:00Z to 2020-12-31T23:59:59.999Z   \n",
       "3     NaN  2005-06-16T00:00:00Z to 2020-12-31T23:59:59.999Z   \n",
       "4     NaN  2005-09-16T00:00:00Z to 2020-12-31T23:59:59.999Z   \n",
       "\n",
       "         Date_Published           data_start_date             data_end_date  \n",
       "0  2016-11-23T00:00:00Z 2005-06-16 00:00:00+00:00 2021-01-01 00:00:00+00:00  \n",
       "1  2017-09-09T00:00:00Z 2015-02-14 00:00:00+00:00 2019-02-07 00:00:00+00:00  \n",
       "2  2016-11-23T00:00:00Z 2005-06-16 00:00:00+00:00 2021-01-01 00:00:00+00:00  \n",
       "3  2016-11-22T00:00:00Z 2005-06-16 00:00:00+00:00 2021-01-01 00:00:00+00:00  \n",
       "4  2016-11-23T00:00:00Z 2005-09-16 00:00:00+00:00 2021-01-01 00:00:00+00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df[['data_start_date','data_end_date']] = df['Data_Date_Range'].str.split(' to ',expand=True)\n",
    "df['data_start_date'] = pd.to_datetime(df['data_start_date'])\n",
    "df['data_end_date'] = pd.to_datetime(df['data_end_date']) + pd.Timedelta(np.timedelta64(1, \"ms\"))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets pull out all the ISO metadata record links and print them out so the user can browse to the metadata record and look for what items they might be interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 records\n",
      "http://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.nodc%3A0157035/xml\n",
      "http://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.nodc%3A0166465/xml\n",
      "http://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.nodc%3A0157034/xml\n",
      "http://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.nodc%3A0157016/xml\n",
      "http://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.nodc%3A0157036/xml\n"
     ]
    }
   ],
   "source": [
    "# parse the csv response\n",
    "\n",
    "print(\"Found %i records\" % len(df))\n",
    "for item in df['Link_Xml']:\n",
    "    print(item)  # URL to ISO19115-2 record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets plot up what we have found\n",
    "Now that we have all the ISO metadata records we are interested in, it's time to do something fun with them. In this example we want to generate a timeseries plot of the data coverage for the \"Southern California Coastal Ocean Observing System\" stations we have archived at NCEI.\n",
    "\n",
    "First we set up the figure and import some modules to facilitate plotting and string parsing.\n",
    "\n",
    "Next, we loop through each iso record to collect metadata information about each package. The example here shows how to collect the following items:\n",
    "   1. NCEI Archival Information Package (AIP) Accession ID (7-digit Accession Number) \n",
    "   2. The first date the archive package was published.\n",
    "   3. The platform code identified from the provider.\n",
    "   4. The version number and date it was published.\n",
    "   5. The current AIP size, in MB.\n",
    "   6. The bounding time, for each AIP found.\n",
    "\n",
    "There are plenty of other metadata elements to collect from the ISO records, so we recommend browsing to one of the records and having a look at the items of interest to your community.\n",
    "\n",
    "Then, the process plots each AIP as a timeseries showing the time coverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First published date = 2016-11-23\n",
      "Accession: 0157035\n",
      "Provider Platform Code = Scripps Pier\n",
      "NCEI Accession 0157035 v1.1 = 2016-11-23T16:08:35Z\n",
      "NCEI Accession 0157035 v2.2 = 2017-01-02T07:17:24Z\n",
      "NCEI Accession 0157035 v3.3 = 2017-02-02T07:16:15Z\n",
      "NCEI Accession 0157035 v4.4 = 2018-01-03T15:41:08Z\n",
      "NCEI Accession 0157035 v5.5 = 2018-02-02T07:17:11Z\n",
      "NCEI Accession 0157035 v6.6 = 2019-02-02T07:18:25Z\n",
      "NCEI Accession 0157035 v7.7 = 2020-03-02T07:37:32Z\n",
      "NCEI Accession 0157035 v8.8 = 2021-02-03T07:29:26Z\n",
      "Current AIP Size = 53.212 MB\n",
      "First published date = 2017-09-09\n",
      "Accession: 0166465\n",
      "Provider Platform Code = Burkolator, Carlsbad Aquafarm\n",
      "NCEI Accession 0166465 v1.1 = 2017-09-09T12:37:07Z\n",
      "NCEI Accession 0166465 v2.2 = 2018-04-02T07:17:09Z\n",
      "NCEI Accession 0166465 v3.3 = 2019-02-02T07:17:33Z\n",
      "NCEI Accession 0166465 v4.4 = 2020-02-04T16:27:36Z\n",
      "Current AIP Size = 53.38 MB\n",
      "First published date = 2016-11-23\n",
      "Accession: 0157034\n",
      "Provider Platform Code = Newport Pier\n",
      "NCEI Accession 0157034 v1.1 = 2016-11-23T16:08:27Z\n",
      "NCEI Accession 0157034 v2.2 = 2017-01-02T07:16:19Z\n",
      "NCEI Accession 0157034 v3.3 = 2017-05-08T15:26:17Z\n",
      "NCEI Accession 0157034 v4.4 = 2018-01-03T14:43:19Z\n",
      "NCEI Accession 0157034 v5.5 = 2018-04-02T07:17:26Z\n",
      "NCEI Accession 0157034 v6.6 = 2019-05-02T07:28:52Z\n",
      "NCEI Accession 0157034 v7.7 = 2019-10-02T16:02:31Z\n",
      "NCEI Accession 0157034 v8.8 = 2020-03-02T07:24:44Z\n",
      "NCEI Accession 0157034 v9.9 = 2021-02-03T07:23:31Z\n",
      "Current AIP Size = 72.612 MB\n",
      "First published date = 2016-11-22\n",
      "Accession: 0157016\n",
      "Provider Platform Code = Santa Monica Pier\n",
      "NCEI Accession 0157016 v1.1 = 2016-11-22T13:03:12Z\n",
      "NCEI Accession 0157016 v2.2 = 2017-01-02T07:17:15Z\n",
      "NCEI Accession 0157016 v3.3 = 2018-01-03T15:18:08Z\n",
      "NCEI Accession 0157016 v4.4 = 2019-05-02T07:42:06Z\n",
      "NCEI Accession 0157016 v5.5 = 2020-03-02T07:30:19Z\n",
      "NCEI Accession 0157016 v6.6 = 2021-02-03T07:26:22Z\n",
      "Current AIP Size = 40.952 MB\n",
      "First published date = 2016-11-23\n",
      "Accession: 0157036\n",
      "Provider Platform Code = Stearns Wharf\n",
      "NCEI Accession 0157036 v1.1 = 2016-11-23T16:08:43Z\n",
      "NCEI Accession 0157036 v2.2 = 2017-01-02T07:17:32Z\n",
      "NCEI Accession 0157036 v3.3 = 2017-02-02T07:17:14Z\n",
      "NCEI Accession 0157036 v4.4 = 2018-01-03T15:43:08Z\n",
      "NCEI Accession 0157036 v5.5 = 2018-02-02T07:18:09Z\n",
      "NCEI Accession 0157036 v6.6 = 2019-02-02T07:19:22Z\n",
      "NCEI Accession 0157036 v7.7 = 2019-03-02T07:48:05Z\n",
      "NCEI Accession 0157036 v8.8 = 2020-03-02T07:44:30Z\n",
      "NCEI Accession 0157036 v9.9 = 2021-02-03T07:32:26Z\n",
      "Current AIP Size = 49.064 MB\n"
     ]
    }
   ],
   "source": [
    "# Process each iso record.\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from owslib import util\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "#i = 0\n",
    "accenos = []\n",
    "\n",
    "df[['provider_platform_name','NCEI_accession_number','package_size_mb']] = ''\n",
    "\n",
    "# For each accession in response.\n",
    "for url in df['Link_Xml']:\n",
    "\n",
    "    iso = urlopen(url)\n",
    "    iso_tree = ET.parse(iso)\n",
    "    root = iso_tree.getroot()\n",
    "\n",
    "    # Collect Publication date information.\n",
    "    date_path = (\n",
    "        \".//\"\n",
    "        \"gmd:identificationInfo/\"\n",
    "        \"gmd:MD_DataIdentification/\"\n",
    "        \"gmd:citation/\"\n",
    "        \"gmd:CI_Citation/\"\n",
    "        \"gmd:date/\"\n",
    "        \"gmd:CI_Date/\"\n",
    "        \"gmd:date/gco:Date\"\n",
    "    )\n",
    "    # First published date.\n",
    "    pubdate = root.find(date_path, namespaces)\n",
    "    print(\"First published date = %s\" % util.testXMLValue(pubdate))\n",
    "\n",
    "    # Collect keyword terms of interest.\n",
    "    for MD_keywords in root.iterfind('.//gmd:descriptiveKeywords/gmd:MD_Keywords', namespaces):\n",
    "\n",
    "        for thesaurus_name in MD_keywords.iterfind('.//gmd:thesaurusName/gmd:CI_Citation/gmd:title/gco:CharacterString', namespaces):\n",
    "            \n",
    "            if thesaurus_name.text == \"Provider Platform Names\":\n",
    "\n",
    "                plat_name = MD_keywords.find('.//gmd:keyword/gco:CharacterString', namespaces).text\n",
    "                print(\"Provider Platform Code = %s\" % plat_name)\n",
    "                df.loc[df.Link_Xml == url, ['provider_platform_name']] = plat_name\n",
    "                break\n",
    "                \n",
    "            elif thesaurus_name.text == \"NCEI ACCESSION NUMBER\":\n",
    "                acce_no = MD_keywords.find('.//gmd:keyword/gmx:Anchor', namespaces).text\n",
    "                accenos.append(acce_no)\n",
    "                print(\"Accession:\",acce_no)\n",
    "                df.loc[df.Link_Xml == url, ['NCEI_accession_number']] = acce_no\n",
    "                break\n",
    "            \n",
    "\n",
    "    # Pull out the version information.\n",
    "    # Iterate through each processing step which is an NCEI version.\n",
    "    for process_step in root.iterfind(\".//gmd:processStep\", namespaces):\n",
    "        # Only parse gco:DateTime and gmd:title/gco:CharacterString.\n",
    "        vers_title = (\n",
    "            \".//\"\n",
    "            \"gmi:LE_ProcessStep/\"\n",
    "            \"gmi:output/\"\n",
    "            \"gmi:LE_Source/\"\n",
    "            \"gmd:sourceCitation/\"\n",
    "            \"gmd:CI_Citation/\"\n",
    "            \"gmd:title/\"\n",
    "            \"gco:CharacterString\"\n",
    "        )\n",
    "        vers_date = (\n",
    "            \".//\" \n",
    "            \"gmi:LE_ProcessStep/\" \n",
    "            \"gmd:dateTime/\"\n",
    "            \"gco:DateTime\"\n",
    "        )\n",
    "        if process_step.findall(vers_date, namespaces) and process_step.findall(vers_title, namespaces):\n",
    "            # Extract dateTime for each version.\n",
    "            datetimes = process_step.findall(vers_date, namespaces)\n",
    "            # Extract title string (contains version number).\n",
    "            titles = process_step.findall(vers_title, namespaces)\n",
    "            print(\n",
    "                \"{} = {}\".format(\n",
    "                    util.testXMLValue(titles[0]), util.testXMLValue(datetimes[0])\n",
    "                )\n",
    "            )\n",
    "            df.loc[df.Link_Xml == url, ['version_info']] = \"{} = {}\".format(\n",
    "                    util.testXMLValue(titles[0]), util.testXMLValue(datetimes[0]))\n",
    "\n",
    "    # Collect package size information.\n",
    "    # Iterate through transfersize nodes.\n",
    "    for trans_size in root.iterfind(\".//gmd:transferSize\", namespaces):\n",
    "\n",
    "        if trans_size.find(\".//gco:Real\", namespaces).text:\n",
    "            \n",
    "            sizes = trans_size.find(\".//gco:Real\", namespaces).text\n",
    "            print(\"Current AIP Size = %s MB\" % sizes)\n",
    "                \n",
    "            df.loc[df.Link_Xml == url, ['package_size_mb']] = float(sizes)\n",
    "            break\n",
    "\n",
    "        break\n",
    "\n",
    "#     # Bounding time for AIP.\n",
    "#     for time_period in root.iterfind(\".//gml:TimePeriod\", namespaces):\n",
    "\n",
    "#         if (time_period.find(\".//gml:beginPosition\", namespaces).text and \n",
    "#             time_period.find(\".//gml:endPosition\", namespaces).text):\n",
    "            \n",
    "#             start_date = time_period.find(\".//gml:beginPosition\", namespaces).text\n",
    "#             end_date = time_period.find(\".//gml:endPosition\", namespaces).text\n",
    "\n",
    "#         print(\"Bounding Time = %s TO %s\\n\" % (start_date, end_date)) \n",
    "\n",
    "#     # Plotting routine for each accession, plot start-end as timeseries for each accession.\n",
    "#     # Create datetime objects for start_date and end_date.\n",
    "#     date1 = datetime(\n",
    "#         int(start_date.split(\"-\")[0]),\n",
    "#         int(start_date.split(\"-\")[1]),\n",
    "#         int(start_date.split(\"-\")[2]),\n",
    "#     )\n",
    "#     date2 = datetime(\n",
    "#         int(end_date.split(\"-\")[0]),\n",
    "#         int(end_date.split(\"-\")[1]),\n",
    "#         int(end_date.split(\"-\")[2]),\n",
    "#     )\n",
    "#     dates = [date1, date2]\n",
    "#     i += 1  # Counter for plotting.\n",
    "#     y = [i, i]\n",
    "#     # Plot the timeseries.\n",
    "#     ax.plot_date(x=dates, y=y, fmt=\"-\", color=\"b\", linewidth=6.0)\n",
    "\n",
    "# # Clean up the plot.\n",
    "# ax.set_ylim([0, i + 1])\n",
    "# years = mdates.YearLocator()\n",
    "# months = mdates.MonthLocator()\n",
    "# yearsFmt = mdates.DateFormatter(\"%Y\")\n",
    "# ax.xaxis.grid(True)\n",
    "# ax.xaxis.set_major_locator(years)\n",
    "# ax.xaxis.set_major_formatter(yearsFmt)  # Format the xaxis labels.\n",
    "# ax.xaxis.set_minor_locator(months)\n",
    "# ax.xaxis.set_ticks_position(\"bottom\")\n",
    "# ax.yaxis.grid(True)\n",
    "# ax.set(yticks=np.arange(1, len(accenos) + 1))\n",
    "# ax.tick_params(which=\"both\", direction=\"out\")\n",
    "# ax.set_yticklabels(accenos)\n",
    "# plt.ylabel(\"NCEI Accession Number\")\n",
    "# title = ax.set_title(\"%s Data Archived at NCEI\" % ra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This procedure has been developed as an example of how to use NCEI's geoportal REST API's to collect information about packages that have been archived at NCEI. The intention is to provide some guidance and ways to collect this information without having to request it directly from NCEI. There are a significant amount of metadata elements which NCEI makes available through their ISO metadata records. Therefore, anyone interested in collecting other information from the records at NCEI should have a look at the ISO metadata records and determine which items are of interest to their community. Then, update the example code provided to collect that information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see this link:\n",
    "# https://stackoverflow.com/questions/11042290/how-can-i-use-xaxis-date-with-barh\n",
    "# fiddle with this to creat bar time plot as above ^\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def drange(start, end, interval=dt.timedelta(days=1)):\n",
    "    output = []\n",
    "    while start <= end:\n",
    "        output.append(start)\n",
    "        start += interval\n",
    "    return output\n",
    "\n",
    "# Generate a series of dates for plotting...\n",
    "edate = drange(dt.datetime(2012, 2, 1), dt.datetime(2012, 6, 15), \n",
    "                      dt.timedelta(days=50))\n",
    "bdate = drange(dt.datetime(2012, 1, 1), dt.datetime(2012, 5, 15), \n",
    "                      dt.timedelta(days=50))\n",
    "\n",
    "# Now convert them to matplotlib's internal format...\n",
    "edate, bdate = [mdates.date2num(item) for item in (edate, bdate)]\n",
    "\n",
    "ypos = range(len(edate))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data\n",
    "ax.barh(ypos, edate - bdate, left=bdate, height=0.8, align='center')\n",
    "ax.axis('tight')\n",
    "\n",
    "# We need to tell matplotlib that these are dates...\n",
    "ax.xaxis_date()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b128ab07cf20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot date ranges for each accession, maybe groupby?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data_start_date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCEI_accession_number'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\programs\\Anaconda3\\envs\\IOOS\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mother\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmeasured\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \"\"\"\n\u001b[1;32m-> 1113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bar\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     @Appender(\n",
      "\u001b[1;32m~\\programs\\Anaconda3\\envs\\IOOS\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\Anaconda3\\envs\\IOOS\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\Anaconda3\\envs\\IOOS\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\Anaconda3\\envs\\IOOS\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# no non-numeric frames or series allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no numeric data to plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "# plot date ranges for each accession, maybe groupby?\n",
    "df.plot.barh(x='data_start_date',y='NCEI_accession_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
